{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gmauricio-toledo/NLP-LCC/blob/main/Notebooks/06-Vectores_sem%C3%A1nticos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Semántica Vectorial</h1>\n",
        "\n",
        "En esta notebook usaremos dos módelos de semántica vectorial para diversas tareas de NLP. Los modelos que usaremos son:\n",
        "\n",
        "* Bag of Words (BoW). [`CountVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)\n",
        "* Term Frequency - Inverse Document Frequency (TF-IDF). [`TfidfVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
        "\n",
        "Usando estos dos modelos realicermos tareas como:\n",
        "\n",
        "* Vecinos más cercanos\n",
        "* Information Retrieval\n",
        "* Segmentación\n",
        "* Clasificación\n"
      ],
      "metadata": {
        "id": "flcPOaSE3dZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import nltk\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "b7x0zZC6NSdF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "209e74cc-4f94-4845-c988-9f6f913f214b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Corpus 0: Detección de SPAM"
      ],
      "metadata": {
        "id": "u613pEDMA0gQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1-pMLSTkJ3ZPCKQU8oXA3uI-swvXw7DmJ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lq0P-lmyA0U9",
        "outputId": "6158a7c3-aae8-4467-80cb-50ca94e1a431"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-pMLSTkJ3ZPCKQU8oXA3uI-swvXw7DmJ\n",
            "To: /content/Spam_SMS.csv\n",
            "\r  0% 0.00/487k [00:00<?, ?B/s]\r100% 487k/487k [00:00<00:00, 35.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('Spam_SMS.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "HoWfqj-bBZCq",
        "outputId": "919a5795-b198-4ba8-8d24-c7ee0f289499"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Class                                            Message\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
              "...    ...                                                ...\n",
              "5569  spam  This is the 2nd time we have tried 2 contact u...\n",
              "5570   ham               Will ü b going to esplanade fr home?\n",
              "5571   ham  Pity, * was in mood for that. So...any other s...\n",
              "5572   ham  The guy did some bitching but I acted like i'd...\n",
              "5573   ham                         Rofl. Its true to its name\n",
              "\n",
              "[5574 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fe60882e-6937-4f21-b935-0ea9e0012e58\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class</th>\n",
              "      <th>Message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will ü b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5572</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5573</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5574 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fe60882e-6937-4f21-b935-0ea9e0012e58')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fe60882e-6937-4f21-b935-0ea9e0012e58 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fe60882e-6937-4f21-b935-0ea9e0012e58');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_d812049e-7b31-4611-b4b9-199cb95d2be9\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d812049e-7b31-4611-b4b9-199cb95d2be9 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5574,\n  \"fields\": [\n    {\n      \"column\": \"Class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Message\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5159,\n        \"samples\": [\n          \"\\\"HEY KATE, HOPE UR OK... WILL GIVE U A BUZ WEDLUNCH. GO OUTSOMEWHERE 4 ADRINK IN TOWN..CUD GO 2WATERSHD 4 A BIT? PPL FROMWRK WILL BTHERE. LOVE PETEXXX.\\\"\",\n          \"Nobody names their penis a girls name this story doesn't add up at all\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in df.sample(10).index.to_list():\n",
        "    print(df.loc[idx,'Message'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mI5X1tKdBlLP",
        "outputId": "44fff814-d1dc-40c1-8340-594ba31aa223"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your opinion about me? 1. Over 2. Jada 3. Kusruthi 4. Lovable 5. Silent 6. Spl character 7. Not matured 8. Stylish 9. Simple Pls reply..\n",
            "Please leave this topic..sorry for telling that..\n",
            "A little. Meds say take once every 8 hours. It's only been 5 but pain is back. So I took another. Hope I don't die\n",
            "Or u ask they all if next sat can a not. If all of them can make it then i'm ok lor.\n",
            "GSOH? Good with SPAM the ladies?U could b a male gigolo? 2 join the uk's fastest growing mens club reply ONCALL. mjzgroup. 08714342399.2stop reply STOP. msg@£1.50rcvd\n",
            "Alright. I'm out--have a good night!\n",
            "No we sell it all so we'll have tons if coins. Then sell our coins to someone thru paypal. Voila! Money back in life pockets:)\n",
            "Just so that you know,yetunde hasn't sent money yet. I just sent her a text not to bother sending. So its over, you dont have to involve yourself in anything. I shouldn't have imposed anything on you in the first place so for that, i apologise.\n",
            "Ofcourse I also upload some songs\n",
            "8007 FREE for 1st week! No1 Nokia tone 4 ur mob every week just txt NOKIA to 8007 Get txting and tell ur mates www.getzed.co.uk POBox 36504 W4 5WQ norm 150p/tone 16+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "from nltk import word_tokenize\n",
        "import re\n",
        "\n",
        "def limpiar_texto(texto):\n",
        "    texto = texto.lower()\n",
        "    texto = re.sub(r'[^\\w\\s]', '', texto)\n",
        "    texto = re.sub(r'\\d+', ' ', texto)\n",
        "    tokens = word_tokenize(texto)\n",
        "    # tokens = [token for token in tokens if token not in punctuation]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "df['texto limpio'] = df['Message'].apply(limpiar_texto)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "G4HbA345BiP7",
        "outputId": "2d478532-e93e-4f8c-a0e0-fd9c7dc7fcc7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Class                                            Message  \\\n",
              "0      ham  Go until jurong point, crazy.. Available only ...   \n",
              "1      ham                      Ok lar... Joking wif u oni...   \n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
              "3      ham  U dun say so early hor... U c already then say...   \n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...   \n",
              "...    ...                                                ...   \n",
              "5569  spam  This is the 2nd time we have tried 2 contact u...   \n",
              "5570   ham               Will ü b going to esplanade fr home?   \n",
              "5571   ham  Pity, * was in mood for that. So...any other s...   \n",
              "5572   ham  The guy did some bitching but I acted like i'd...   \n",
              "5573   ham                         Rofl. Its true to its name   \n",
              "\n",
              "                                           texto limpio  \n",
              "0     go until jurong point crazy available only in ...  \n",
              "1                               ok lar joking wif u oni  \n",
              "2     free entry in a wkly comp to win fa cup final ...  \n",
              "3           u dun say so early hor u c already then say  \n",
              "4     nah i dont think he goes to usf he lives aroun...  \n",
              "...                                                 ...  \n",
              "5569  this is the nd time we have tried contact u u ...  \n",
              "5570                will ü b going to esplanade fr home  \n",
              "5571  pity was in mood for that soany other suggestions  \n",
              "5572  the guy did some bitching but i acted like id ...  \n",
              "5573                          rofl its true to its name  \n",
              "\n",
              "[5574 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1cd43a6b-8c7c-40cc-ad55-5d21b5842049\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class</th>\n",
              "      <th>Message</th>\n",
              "      <th>texto limpio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>go until jurong point crazy available only in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>ok lar joking wif u oni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>free entry in a wkly comp to win fa cup final ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>u dun say so early hor u c already then say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "      <td>this is the nd time we have tried contact u u ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will ü b going to esplanade fr home?</td>\n",
              "      <td>will ü b going to esplanade fr home</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "      <td>pity was in mood for that soany other suggestions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5572</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "      <td>the guy did some bitching but i acted like id ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5573</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "      <td>rofl its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5574 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1cd43a6b-8c7c-40cc-ad55-5d21b5842049')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1cd43a6b-8c7c-40cc-ad55-5d21b5842049 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1cd43a6b-8c7c-40cc-ad55-5d21b5842049');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_adad2759-c14e-48a8-8baf-f5bc3010b456\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_adad2759-c14e-48a8-8baf-f5bc3010b456 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5574,\n  \"fields\": [\n    {\n      \"column\": \"Class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Message\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5159,\n        \"samples\": [\n          \"\\\"HEY KATE, HOPE UR OK... WILL GIVE U A BUZ WEDLUNCH. GO OUTSOMEWHERE 4 ADRINK IN TOWN..CUD GO 2WATERSHD 4 A BIT? PPL FROMWRK WILL BTHERE. LOVE PETEXXX.\\\"\",\n          \"Nobody names their penis a girls name this story doesn't add up at all\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"texto limpio\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5090,\n        \"samples\": [\n          \"i met you as a stranger and choose you as my friend as long as the world stands our friendship never ends lets be friends forever gud nitz\",\n          \"ew are you one of them\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(df['Class'].values)\n",
        "print(y[:5])\n",
        "\n",
        "docs = df['texto limpio'].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zgd90udnBejN",
        "outputId": "b3b00735-d297-4aa4-9ff5-820c6d5984c6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 1 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(X_train_bow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qst1HByCDw3q",
        "outputId": "e5e1bb24-0dd1-4ad2-8601-570973e8b02c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.matrix"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(docs, y,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=12)"
      ],
      "metadata": {
        "id": "tRgUL3ExCx63"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv = CountVectorizer()\n",
        "X_train_bow = cv.fit_transform(X_train).todense()\n",
        "X_train_bow = np.array(X_train_bow)\n",
        "X_test_bow = cv.transform(X_test).todense()\n",
        "X_test_bow = np.array(X_test_bow)"
      ],
      "metadata": {
        "id": "tcy-H_j1C3kP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC(kernel='linear')\n",
        "svm.fit(X_train_bow, y_train)\n",
        "\n",
        "y_pred_train = svm.predict(X_train_bow)\n",
        "y_pred_test = svm.predict(X_test_bow)"
      ],
      "metadata": {
        "id": "MH0q2BonC6dQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Corpus 1: Wikipedia"
      ],
      "metadata": {
        "id": "azUhLD1uMZpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "_9XZLsaW8ASk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora probemos con otro corpus. Es una parte de un dump de wikipedia del 2006 ([información](https://www.cs.upc.edu/~nlp/wikicorpus/))."
      ],
      "metadata": {
        "id": "CU1UkHSt3aCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/gmauricio-toledo/NLP-MCD/main/data/spanish-wikipedia-dataframe.csv\"\n",
        "df = pd.read_csv(url,index_col=0)\n",
        "df"
      ],
      "metadata": {
        "id": "guN3Df38qcdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocesamos y limpiamos el texto.\n",
        "\n",
        "⭕ ¿Qué estamos haciendo al texto?"
      ],
      "metadata": {
        "id": "H9Hi9jbpyUuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs_raw = df['Texto'].tolist()\n",
        "docs = [re.sub(r'\\d+', ' ', doc) for doc in docs_raw]\n",
        "tokenized_docs = [word_tokenize(doc) for doc in docs]\n",
        "docs = [[token for token in doc if token not in nltk.corpus.stopwords.words('spanish')] for doc in tokenized_docs]\n",
        "docs = [' '.join(doc) for doc in docs]\n",
        "docs[:3]"
      ],
      "metadata": {
        "id": "WMj-PyHK6KTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo BOW"
      ],
      "metadata": {
        "id": "vvEb_zN_MyYe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observa cómo especificamos la lista de stopwords en español."
      ],
      "metadata": {
        "id": "0h1hewVvyjGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = nltk.corpus.stopwords.words('spanish')\n",
        "\n",
        "cv = CountVectorizer(stop_words=stop_words, max_features=1000)\n",
        "X_bow = cv.fit_transform(docs)\n",
        "X_bow.shape"
      ],
      "metadata": {
        "id": "O4BFKBhM7s9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_bow[:3,:7].todense()"
      ],
      "metadata": {
        "id": "NAYOhAPejOHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_bow[140:143,750:756].todense()"
      ],
      "metadata": {
        "id": "BEigfAFRjg9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿Qué tan *sparse* es la matriz?"
      ],
      "metadata": {
        "id": "r2dVGFnfrgjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_ceros = np.where(X_bow.toarray()==0)[0].shape[0]\n",
        "total_entradas = (X_bow.toarray().shape[0]*X_bow.toarray().shape[1])\n",
        "\n",
        "print(f\"Número de entradas: {total_entradas}\")\n",
        "print(f\"Proporción de entradas cero: {round(100*num_ceros/total_entradas,2)} %\")"
      ],
      "metadata": {
        "id": "v_le-5Rkrf2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = cv.get_feature_names_out()"
      ],
      "metadata": {
        "id": "hmaakzysxyJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectores de documentos"
      ],
      "metadata": {
        "id": "F_FecHXYM0zz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Representaciones de documentos"
      ],
      "metadata": {
        "id": "2X1AzKRfxBXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc_vectors = X_bow.toarray()"
      ],
      "metadata": {
        "id": "Sdq98skMxAIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspeccionemos los vecinos más cercanos de ciertos documentos"
      ],
      "metadata": {
        "id": "CpkFu2_rbMH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "nn = NearestNeighbors(n_neighbors=5, metric='cosine')\n",
        "nn.fit(doc_vectors)"
      ],
      "metadata": {
        "id": "ezeqFvpnxXLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_number = 189\n",
        "# doc_number = np.random.randint(0, len(docs_raw))\n",
        "\n",
        "print(f\"Consulta:\\n\\t{docs_raw[doc_number]}\\n\")\n",
        "\n",
        "v_doc = doc_vectors[doc_number,:].reshape(-1,)\n",
        "nns = nn.kneighbors([v_doc])\n",
        "print(f\"Vecinos más cercanos: {[idx for idx in nns[1][0]]}\\n\")\n",
        "\n",
        "for idx,dist in zip(nns[1][0],nns[0][0]):\n",
        "    print(f\"Distancia: {round(dist,3)}\")\n",
        "    print(f\"{docs_raw[idx]}\\n\")"
      ],
      "metadata": {
        "id": "RYh7nB7Mxqco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Information Retrieval"
      ],
      "metadata": {
        "id": "j80f_0i-cjXJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspeccionemos los vecinos más cercanos de una query"
      ],
      "metadata": {
        "id": "lelQ6e8MbQZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"sello discográfico de artistas de pop\"\n",
        "\n",
        "query_vector = cv.transform([query]).toarray().reshape(-1,)\n",
        "print(query_vector)\n",
        "\n",
        "responses = nn.kneighbors([query_vector])\n",
        "for idx,dist in zip(responses[1][0],responses[0][0]):\n",
        "    print(f\"Distancia: {round(dist,3)}\")\n",
        "    print(f\"{docs_raw[idx]}\\n\")"
      ],
      "metadata": {
        "id": "mmHiDj0qbThw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Grafiquemos la reducción de dimensionalidad 3d t-SNE\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "tsne = TSNE(n_components=3, metric='cosine')\n",
        "X_tsne = tsne.fit_transform(doc_vectors)\n",
        "\n",
        "plotly.offline.init_notebook_mode()\n",
        "\n",
        "trace = go.Scatter3d(\n",
        "    x=X_tsne[:,0],\n",
        "    y=X_tsne[:,1],\n",
        "    z=X_tsne[:,2],\n",
        "    mode='markers',\n",
        "    marker={\n",
        "        'size': 3,\n",
        "        'opacity': 0.75,\n",
        "        'color': 'black'\n",
        "    },\n",
        "    hovertemplate='%{text}<extra></extra>',\n",
        "    text = [f\"{docs_raw[j][:75]}\" for j in range(X_tsne.shape[0])]\n",
        ")\n",
        "\n",
        "layout = go.Layout(\n",
        "    margin={'l': 0, 'r': 0, 'b': 0, 't': 0}\n",
        ")\n",
        "\n",
        "data = [trace]\n",
        "\n",
        "plot_figure = go.Figure(data=data, layout=layout)\n",
        "\n",
        "plot_figure.update_layout(\n",
        "    title = 'Wikipedia Docs',\n",
        "    scene = dict(\n",
        "        xaxis = dict(visible=False),\n",
        "        yaxis = dict(visible=False),\n",
        "        zaxis =dict(visible=False)\n",
        "        )\n",
        "    )\n",
        "\n",
        "plotly.offline.plot(plot_figure, filename='wiki-bow-tsne3d-docs.html')"
      ],
      "metadata": {
        "id": "j2OMOMJvxx4Y",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clustering: Topic Modelling\n",
        "\n",
        "Clustericemos los documentos. Usemos un método basado en densidad, en lugar de uno de partición."
      ],
      "metadata": {
        "id": "EywlAKiUX1ie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "dbscan = DBSCAN(eps=0.1, min_samples=3, metric='cosine')\n",
        "dbscan.fit(doc_vectors)\n",
        "num_doc_clusters = np.max(dbscan.labels_)+1\n",
        "print(f\"Hay {num_doc_clusters} clusters\")"
      ],
      "metadata": {
        "id": "Lg2aPErmYGrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq wordcloud"
      ],
      "metadata": {
        "id": "jUiJ_o9QE2wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title función para factorizar\n",
        "import math\n",
        "\n",
        "def factor_int(n):\n",
        "    val = math.ceil(math.sqrt(n))\n",
        "    val2 = int(n/val)\n",
        "    while val2 * val != float(n):\n",
        "        val -= 1\n",
        "        val2 = int(n/val)\n",
        "    return val, val2"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cWPEj56HaRFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploremos los términos más frecuentes en cada cluster."
      ],
      "metadata": {
        "id": "UXgfgCC8zITk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "idxs_per_cluster = {j: np.where(dbscan.labels_==j)[0] for j in range(num_doc_clusters)}\n",
        "docs_per_cluster = {j: [docs[idx] for idx in idxs_per_cluster[j]] for j in idxs_per_cluster.keys()}\n",
        "\n",
        "wc = WordCloud(background_color=\"white\", max_words=1000)\n",
        "\n",
        "w, h = factor_int(num_doc_clusters)\n",
        "fig, axs = plt.subplots(w, h, figsize=(6*w, 3*h))\n",
        "\n",
        "for j,ax in zip(idxs_per_cluster.keys(),axs.flatten()):\n",
        "    wc.generate(' '.join(docs_per_cluster[j]))\n",
        "    ax.imshow(wc, interpolation='bilinear')\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(f\"Cluster {j}\")\n",
        "fig.tight_layout()\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "ysPfYvM0Z2aP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectores de palabras"
      ],
      "metadata": {
        "id": "6_FnZQc4M3Xv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora veamos las palabras:"
      ],
      "metadata": {
        "id": "4a0iiH-m6jKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word_vector(word):\n",
        "    idx = np.where(vocabulary==word)[0][0]\n",
        "    return X_bow[:, idx].toarray().flatten()"
      ],
      "metadata": {
        "id": "bpTc1Edw2XJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors = [get_word_vector(word) for word in vocabulary]\n",
        "word_vectors = np.array(word_vectors)\n",
        "word_vectors.shape"
      ],
      "metadata": {
        "id": "b92R6nFa6nXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "nn = NearestNeighbors(n_neighbors=5, metric='cosine')\n",
        "nn.fit(word_vectors)"
      ],
      "metadata": {
        "id": "hfcgse0E6y_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probemos los vecinos más cercanos de las palabras: cine, equipo, guerra, música, mayores"
      ],
      "metadata": {
        "id": "ZvtZiisy68wb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word = 'guerra'\n",
        "v = get_word_vector(word)\n",
        "nns = nn.kneighbors([v])\n",
        "print(f\"Vecinos más cercanos: {[vocabulary[idx] for idx in nns[1][0]]}\")\n",
        "print(f\"Distancias: {[round(sim,3) for sim in nns[0][0]]}\")"
      ],
      "metadata": {
        "id": "p8ygy9qh63N9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Grafiquemos la reducción de dimensionalidad 3d t-SNE\n",
        "\n",
        "tsne = TSNE(n_components=3, metric='cosine')\n",
        "X_tsne = tsne.fit_transform(word_vectors)\n",
        "\n",
        "plotly.offline.init_notebook_mode()\n",
        "\n",
        "trace = go.Scatter3d(\n",
        "    x=X_tsne[:,0],\n",
        "    y=X_tsne[:,1],\n",
        "    z=X_tsne[:,2],\n",
        "    mode='markers',\n",
        "    marker={\n",
        "        'size': 3,\n",
        "        'opacity': 0.75,\n",
        "        'color': 'black'\n",
        "    },\n",
        "    hovertemplate='%{text}<extra></extra>',\n",
        "    text = [f\"{vocabulary[j]}\" for j in range(X_tsne.shape[0])]\n",
        ")\n",
        "\n",
        "layout = go.Layout(\n",
        "    margin={'l': 0, 'r': 0, 'b': 0, 't': 0}\n",
        ")\n",
        "\n",
        "data = [trace]\n",
        "\n",
        "plot_figure = go.Figure(data=data, layout=layout)\n",
        "\n",
        "plot_figure.update_layout(\n",
        "    title = 'Wikipedia Words',\n",
        "    scene = dict(\n",
        "        xaxis = dict(visible=False),\n",
        "        yaxis = dict(visible=False),\n",
        "        zaxis =dict(visible=False)\n",
        "        )\n",
        "    )\n",
        "\n",
        "plotly.offline.plot(plot_figure, filename='wiki-bow-tsne3d-words.html')"
      ],
      "metadata": {
        "id": "bO_Kh_BX65w5",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq umap-learn\n",
        "\n",
        "import umap"
      ],
      "metadata": {
        "id": "YP2x6N1oWZqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clustering\n",
        "\n",
        "Analicemos algunos clusters de palabras"
      ],
      "metadata": {
        "id": "IHhkW9AoM7Wg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "n_clusters = 5\n",
        "\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init='auto')\n",
        "kmeans.fit(word_vectors)"
      ],
      "metadata": {
        "id": "IBWx39A79P4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for j in range(n_clusters):\n",
        "    print(f\"Cluster {j}:\")\n",
        "    print([vocabulary[idx] for idx in np.where(kmeans.labels_==j)[0]])"
      ],
      "metadata": {
        "id": "i-5YmojmAGrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analicemos los casos de *familia*, *campeón*"
      ],
      "metadata": {
        "id": "_vyUZ15eUsbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word = 'campeón'\n",
        "v = get_word_vector(word)\n",
        "nns = nn.kneighbors([v])\n",
        "print(f\"Vecinos más cercanos: {[vocabulary[idx] for idx in nns[1][0]]}\")\n",
        "print(f\"Distancias: {[round(sim,3) for sim in nns[0][0]]}\")"
      ],
      "metadata": {
        "id": "5krkhnQEUfgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭕ ¿Por qué tenemos estos resultados que no corresponden a la gráfica?"
      ],
      "metadata": {
        "id": "5WXrK6NRM9Nv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "agglom = AgglomerativeClustering(n_clusters=n_clusters, metric='cosine',linkage='average')\n",
        "agglom.fit(word_vectors)"
      ],
      "metadata": {
        "id": "A5glrXlqVuvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for j in range(n_clusters):\n",
        "    print(f\"Cluster {j}:\")\n",
        "    print([vocabulary[idx] for idx in np.where(agglom.labels_==j)[0]])"
      ],
      "metadata": {
        "id": "-g-FcKFHV_0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word = 'abril'\n",
        "v = get_word_vector(word)\n",
        "nns = nn.kneighbors([v])\n",
        "print(f\"Vecinos más cercanos: {[vocabulary[idx] for idx in nns[1][0]]}\")\n",
        "print(f\"Distancias: {[round(sim,3) for sim in nns[0][0]]}\")"
      ],
      "metadata": {
        "id": "QBVZ0xadAub4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "dbscan = DBSCAN(eps=0.35, min_samples=2, metric='cosine')\n",
        "dbscan.fit(word_vectors)"
      ],
      "metadata": {
        "id": "vY6Ncqh6WS93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for j in np.unique(dbscan.labels_):\n",
        "    print(f\"Cluster {j}:\")\n",
        "    print([vocabulary[idx] for idx in np.where(dbscan.labels_==j)[0]])"
      ],
      "metadata": {
        "id": "w_GeVTM8Wh3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo TF-IDF"
      ],
      "metadata": {
        "id": "hl7MP-sXNCFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "stop_words = nltk.corpus.stopwords.words('spanish')\n",
        "\n",
        "tfv = TfidfVectorizer(stop_words=stop_words, max_features=1000)\n",
        "X_tfidf = tfv.fit_transform(docs)\n",
        "print(X_tfidf.shape)"
      ],
      "metadata": {
        "id": "f5kIZMolAtJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ver la matriz, ¿es más sparse? Tenía el 94.78% de entradas en 0"
      ],
      "metadata": {
        "id": "m_drPj9NPOk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tota_entradas = X_tfidf.shape[0]*X_tfidf.shape[1]\n",
        "num_ceros = np.where(X_tfidf.toarray()==0)[0].shape[0]\n",
        "\n",
        "print(f\"Número de entradas: {total_entradas}\")\n",
        "print(f\"Proporción de entradas cero: {round(100*num_ceros/total_entradas,2)} %\")"
      ],
      "metadata": {
        "id": "s_cv3Ye9PNVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectores de palabras"
      ],
      "metadata": {
        "id": "LmwP1L1YNGG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = tfv.get_feature_names_out()\n",
        "\n",
        "def get_word_vector(word):\n",
        "    idx = np.where(vocabulary==word)[0][0]\n",
        "    return X_tfidf[:, idx].toarray().flatten()"
      ],
      "metadata": {
        "id": "X93kQn1KK3q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors = [get_word_vector(word) for word in vocabulary]\n",
        "word_vectors = np.array(word_vectors)\n",
        "word_vectors.shape"
      ],
      "metadata": {
        "id": "xSf4WwnMNIBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn = NearestNeighbors(n_neighbors=5, metric='cosine')\n",
        "nn.fit(word_vectors)\n",
        "\n",
        "word = 'años'\n",
        "v = get_word_vector(word)\n",
        "nns = nn.kneighbors([v])\n",
        "print(f\"Vecinos más cercanos: {[vocabulary[idx] for idx in nns[1][0]]}\")\n",
        "print(f\"Distancias: {[round(sim,3) for sim in nns[0][0]]}\")"
      ],
      "metadata": {
        "id": "OU-eACAzNKwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Grafiquemos la reducción de dimensionalidad 3d con t-SNE\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "tsne = TSNE(n_components=3,metric='cosine')\n",
        "X_tsne = tsne.fit_transform(word_vectors)\n",
        "\n",
        "plotly.offline.init_notebook_mode()\n",
        "\n",
        "trace = go.Scatter3d(\n",
        "    x=X_tsne[:,0],\n",
        "    y=X_tsne[:,1],\n",
        "    z=X_tsne[:,2],\n",
        "    mode='markers',\n",
        "    marker={\n",
        "        'size': 3,\n",
        "        'opacity': 0.75,\n",
        "        'color': 'black'\n",
        "    },\n",
        "    hovertemplate='%{text}<extra></extra>',\n",
        "    text = [f\"{vocabulary[j]}\" for j in range(X_tsne.shape[0])]\n",
        ")\n",
        "\n",
        "layout = go.Layout(\n",
        "    margin={'l': 0, 'r': 0, 'b': 0, 't': 0}\n",
        ")\n",
        "\n",
        "data = [trace]\n",
        "\n",
        "plot_figure = go.Figure(data=data, layout=layout)\n",
        "\n",
        "plot_figure.update_layout(\n",
        "    title = 'Wikipedia Words',\n",
        "    scene = dict(\n",
        "        xaxis = dict(visible=False),\n",
        "        yaxis = dict(visible=False),\n",
        "        zaxis =dict(visible=False)\n",
        "        )\n",
        "    )\n",
        "\n",
        "plotly.offline.plot(plot_figure, filename='wiki-tfidf-tsne3d-words.html')"
      ],
      "metadata": {
        "id": "a96oClijNPWo",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectores de documentos"
      ],
      "metadata": {
        "id": "_VCe7pELPIh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc_vectors = X_tfidf.toarray()"
      ],
      "metadata": {
        "id": "MjeD7Sb1PTqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "nn = NearestNeighbors(n_neighbors=5, metric='cosine')\n",
        "nn.fit(doc_vectors)"
      ],
      "metadata": {
        "id": "5h8EyQDNu36X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Information Retrieval"
      ],
      "metadata": {
        "id": "Vhyk1ortvfTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# query = \"sello discográfico de artistas de pop\"\n",
        "query = \"acontecimientos importantes en abril o nacido en abril\"\n",
        "\n",
        "query_vector = tfv.transform([query]).toarray().reshape(-1,)\n",
        "\n",
        "if np.sum(query_vector)==0:\n",
        "    print(\"Query no válida (OOV)\")\n",
        "else:\n",
        "    responses = nn.kneighbors([query_vector])\n",
        "    for idx,dist in zip(responses[1][0],responses[0][0]):\n",
        "        print(f\"Distancia: {round(dist,3)}\")\n",
        "        print(f\"{docs_raw[idx]}\\n\")"
      ],
      "metadata": {
        "id": "uAJUc0CbvBV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Reducción de dimensionalidad 3d t-SNE\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "tsne = TSNE(n_components=3, metric='cosine')\n",
        "X_tsne = tsne.fit_transform(doc_vectors)\n",
        "\n",
        "plotly.offline.init_notebook_mode()\n",
        "\n",
        "trace = go.Scatter3d(\n",
        "    x=X_tsne[:,0],\n",
        "    y=X_tsne[:,1],\n",
        "    z=X_tsne[:,2],\n",
        "    mode='markers',\n",
        "    marker={\n",
        "        'size': 3,\n",
        "        'opacity': 0.75,\n",
        "        'color': 'black'\n",
        "    },\n",
        "    hovertemplate='%{text}<extra></extra>',\n",
        "    text = [f\"{docs_raw[j][:75]}\" for j in range(X_tsne.shape[0])]\n",
        ")\n",
        "\n",
        "layout = go.Layout(\n",
        "    margin={'l': 0, 'r': 0, 'b': 0, 't': 0}\n",
        ")\n",
        "\n",
        "data = [trace]\n",
        "\n",
        "plot_figure = go.Figure(data=data, layout=layout)\n",
        "\n",
        "plot_figure.update_layout(\n",
        "    title = 'Wikipedia Docs',\n",
        "    scene = dict(\n",
        "        xaxis = dict(visible=False),\n",
        "        yaxis = dict(visible=False),\n",
        "        zaxis =dict(visible=False)\n",
        "        )\n",
        "    )\n",
        "\n",
        "plotly.offline.plot(plot_figure, filename='wiki-tfidf-tsne3d-docs.html')"
      ],
      "metadata": {
        "id": "tFoJsdzrvFP4",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq umap-learn"
      ],
      "metadata": {
        "id": "gBF9ulo-Id0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Reducción de dimensionalidad 3d UMAP\n",
        "\n",
        "from umap import UMAP\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "umap = UMAP(n_components=3, metric='cosine')\n",
        "X_umap = umap.fit_transform(doc_vectors)\n",
        "\n",
        "plotly.offline.init_notebook_mode()\n",
        "\n",
        "trace = go.Scatter3d(\n",
        "    x=X_umap[:,0],\n",
        "    y=X_umap[:,1],\n",
        "    z=X_umap[:,2],\n",
        "    mode='markers',\n",
        "    marker={\n",
        "        'size': 3,\n",
        "        'opacity': 0.75,\n",
        "        'color': 'black'\n",
        "    },\n",
        "    hovertemplate='%{text}<extra></extra>',\n",
        "    text = [f\"{docs_raw[j][:75]}\" for j in range(X_umap.shape[0])]\n",
        ")\n",
        "\n",
        "layout = go.Layout(\n",
        "    margin={'l': 0, 'r': 0, 'b': 0, 't': 0}\n",
        ")\n",
        "\n",
        "data = [trace]\n",
        "\n",
        "plot_figure = go.Figure(data=data, layout=layout)\n",
        "\n",
        "plot_figure.update_layout(\n",
        "    title = 'Wikipedia Docs',\n",
        "    scene = dict(\n",
        "        xaxis = dict(visible=False),\n",
        "        yaxis = dict(visible=False),\n",
        "        zaxis = dict(visible=False)\n",
        "        )\n",
        "    )\n",
        "\n",
        "plotly.offline.plot(plot_figure, filename='wiki-tfidf-umap3d-docs.html')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "tOv_0DniIZpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clustering"
      ],
      "metadata": {
        "id": "u-f5EGcS2bNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "dbscan = DBSCAN(eps=0.1, min_samples=3, metric='cosine')\n",
        "dbscan.fit(doc_vectors)\n",
        "num_doc_clusters = np.max(dbscan.labels_)+1\n",
        "print(f\"Hay {num_doc_clusters} clusters\")\n",
        "\n",
        "idxs_per_cluster = {j: np.where(dbscan.labels_==j)[0] for j in range(num_doc_clusters)}\n",
        "docs_per_cluster = {j: [docs[idx] for idx in idxs_per_cluster[j]] for j in idxs_per_cluster.keys()}"
      ],
      "metadata": {
        "id": "Xb0a7yfE2bNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "wc = WordCloud(background_color=\"white\", max_words=1000)\n",
        "\n",
        "w, h = factor_int(num_doc_clusters)\n",
        "fig, axs = plt.subplots(w, h, figsize=(6*w, 3*h))\n",
        "\n",
        "for j,ax in zip(idxs_per_cluster.keys(),axs.flatten()):\n",
        "    wc.generate(' '.join(docs_per_cluster[j]))\n",
        "    ax.imshow(wc, interpolation='bilinear')\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(f\"Cluster {j}\")\n",
        "fig.tight_layout()\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "QtvOBJ2y2bNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title visualizar clusters en la reducción de dimensionalidad\n",
        "\n",
        "from umap import UMAP\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "umap = UMAP(n_components=3, metric='cosine')\n",
        "X_umap = umap.fit_transform(doc_vectors)\n",
        "\n",
        "plotly.offline.init_notebook_mode()\n",
        "\n",
        "trace = go.Scatter3d(\n",
        "    x=X_umap[:,0],\n",
        "    y=X_umap[:,1],\n",
        "    z=X_umap[:,2],\n",
        "    mode='markers',\n",
        "    marker={\n",
        "        'size': 3,\n",
        "        'opacity': 0.25,\n",
        "        'color': 'gray'\n",
        "    },\n",
        "    hovertemplate='%{text}<extra></extra>',\n",
        "    text = [f\"{docs_raw[j][:75]}\" for j in range(X_umap.shape[0])]\n",
        ")\n",
        "\n",
        "layout = go.Layout(\n",
        "    margin={'l': 0, 'r': 0, 'b': 0, 't': 0}\n",
        ")\n",
        "\n",
        "data = [trace]\n",
        "\n",
        "plot_figure = go.Figure(data=data, layout=layout)\n",
        "\n",
        "for j in idxs_per_cluster.keys():\n",
        "    Xs = X_umap[idxs_per_cluster[j],0]\n",
        "    Ys = X_umap[idxs_per_cluster[j],1]\n",
        "    Zs = X_umap[idxs_per_cluster[j],2]\n",
        "    plot_figure.add_trace(\n",
        "        go.Scatter3d(\n",
        "            x=Xs,\n",
        "            y=Ys,\n",
        "            z=Zs,\n",
        "            mode='markers',\n",
        "            marker={\n",
        "                'size': 3,\n",
        "                'opacity': 0.75\n",
        "            },\n",
        "            hovertemplate='%{text}<extra></extra>',\n",
        "            text = [f\"{docs_raw[j][:75]}\" for j in range(X_umap.shape[0])]\n",
        "        )\n",
        "    )\n",
        "\n",
        "plot_figure.update_layout(\n",
        "    title = 'Wikipedia Docs',\n",
        "    scene = dict(\n",
        "        xaxis = dict(visible=False),\n",
        "        yaxis = dict(visible=False),\n",
        "        zaxis = dict(visible=False)\n",
        "        )\n",
        "    )\n",
        "\n",
        "plotly.offline.plot(plot_figure, filename='wiki-tfidf-umap3d-docs-clusters.html')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Jr74KegwKnDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Corpus 2: 20newsgroups\n",
        "<h2>Features como clasificación</h2>\n",
        "\n",
        "Finalmente usamos los vectores de documentos como features para un clasificador. Hasta el momento, sólo *sabíamos* hacer la clasificación con los $n$-gramas."
      ],
      "metadata": {
        "id": "izAWHrgV2rVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "# train_docs = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "# test_docs = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "train_docs = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), categories=['sci.med', 'sci.space'])\n",
        "test_docs = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), categories=['sci.med', 'sci.space'])\n",
        "\n",
        "y_train = train_docs.target\n",
        "y_test = test_docs.target\n",
        "\n",
        "y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "MX9836s92tpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_docs.data[0]"
      ],
      "metadata": {
        "id": "aljiJDsCOLiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BoW"
      ],
      "metadata": {
        "id": "m8rsKbVqP7yo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv = CountVectorizer(max_features=1000,stop_words='english')\n",
        "X_train = cv.fit_transform(train_docs.data)\n",
        "X_test = cv.transform(test_docs.data)"
      ],
      "metadata": {
        "id": "xQ37ukmbP7c2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred = lr.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(f\"F1 score: {f1_score(y_test, y_pred, average='weighted')}\")"
      ],
      "metadata": {
        "id": "DEDUACIvQD28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title visualizar clases en la reducción de dimensionalidad\n",
        "!pip install -qq umap-learn\n",
        "\n",
        "from umap import UMAP\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "umap = UMAP(n_components=3, metric='cosine')\n",
        "X_umap = umap.fit_transform(X_train)\n",
        "\n",
        "plotly.offline.init_notebook_mode()\n",
        "\n",
        "\n",
        "layout = go.Layout(\n",
        "    margin={'l': 0, 'r': 0, 'b': 0, 't': 0}\n",
        ")\n",
        "\n",
        "plot_figure = go.Figure(layout=layout)\n",
        "\n",
        "for j in np.unique(y_train):\n",
        "    Xs = X_umap[y_train==j,0].reshape(-1,)\n",
        "    Ys = X_umap[y_train==j,1].reshape(-1,)\n",
        "    Zs = X_umap[y_train==j,2].reshape(-1,)\n",
        "    plot_figure.add_trace(\n",
        "        go.Scatter3d(\n",
        "            x=Xs,\n",
        "            y=Ys,\n",
        "            z=Zs,\n",
        "            mode='markers',\n",
        "            marker={\n",
        "                'size': 3,\n",
        "                'opacity': 0.75\n",
        "            },\n",
        "            hovertemplate='%{text}<extra></extra>',\n",
        "            text = [f\"{train_docs.data[j][:75]}\" for j in range(Xs.shape[0])],\n",
        "            name = train_docs.target_names[j]\n",
        "        )\n",
        "    )\n",
        "\n",
        "plot_figure.update_layout(\n",
        "    scene = dict(\n",
        "        xaxis = dict(visible=False),\n",
        "        yaxis = dict(visible=False),\n",
        "        zaxis = dict(visible=False)\n",
        "        )\n",
        "    )\n",
        "\n",
        "plotly.offline.plot(plot_figure, filename='20ng-bow-umap3d-docs-classes.html')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "nc4kLZXCQMRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tf-idf"
      ],
      "metadata": {
        "id": "fpO6P5CoP5KI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "cv = TfidfVectorizer(max_features=1000,stop_words='english')\n",
        "X_train = cv.fit_transform(train_docs.data)\n",
        "X_test = cv.transform(test_docs.data)"
      ],
      "metadata": {
        "id": "TC6M_pkG3kPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "y_pred = lr.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(f\"F1 score: {f1_score(y_test, y_pred, average='weighted')}\")"
      ],
      "metadata": {
        "id": "I9A7jVHZC6VJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al usar un método interpretable, como regresión logística, podemos obtener la importancia de las variables, en este caso, las palabras del vocabulario."
      ],
      "metadata": {
        "id": "tPEyOpkGuwNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr.coef_.shape"
      ],
      "metadata": {
        "id": "-A6ewiFoucrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos las palabras que más influyen en la clasificación de la clase *positiva*"
      ],
      "metadata": {
        "id": "AzCqFs3Du9JD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_importance = zip(cv.get_feature_names_out() ,lr.coef_.reshape(-1,))\n",
        "word_importance = sorted(word_importance, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "word_importance[:10]"
      ],
      "metadata": {
        "id": "k6fU5FL9uD3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title visualizar clases en la reducción de dimensionalidad\n",
        "\n",
        "from umap import UMAP\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "umap = UMAP(n_components=3, metric='cosine')\n",
        "X_umap = umap.fit_transform(X_train)\n",
        "\n",
        "plotly.offline.init_notebook_mode()\n",
        "\n",
        "\n",
        "layout = go.Layout(\n",
        "    margin={'l': 0, 'r': 0, 'b': 0, 't': 0}\n",
        ")\n",
        "\n",
        "plot_figure = go.Figure(layout=layout)\n",
        "\n",
        "for j in np.unique(y_train):\n",
        "    Xs = X_umap[y_train==j,0].reshape(-1,)\n",
        "    Ys = X_umap[y_train==j,1].reshape(-1,)\n",
        "    Zs = X_umap[y_train==j,2].reshape(-1,)\n",
        "    plot_figure.add_trace(\n",
        "        go.Scatter3d(\n",
        "            x=Xs,\n",
        "            y=Ys,\n",
        "            z=Zs,\n",
        "            mode='markers',\n",
        "            marker={\n",
        "                'size': 3,\n",
        "                'opacity': 0.75\n",
        "            },\n",
        "            hovertemplate='%{text}<extra></extra>',\n",
        "            text = [f\"{train_docs.data[j][:75]}\" for j in range(Xs.shape[0])],\n",
        "            name = train_docs.target_names[j]\n",
        "        )\n",
        "    )\n",
        "\n",
        "plot_figure.update_layout(\n",
        "    scene = dict(\n",
        "        xaxis = dict(visible=False),\n",
        "        yaxis = dict(visible=False),\n",
        "        zaxis = dict(visible=False)\n",
        "        )\n",
        "    )\n",
        "\n",
        "plotly.offline.plot(plot_figure, filename='20ng-tfidf-umap3d-docs-classes.html')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "C3q11cisNXOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🟥 Ejercicios Adicionales"
      ],
      "metadata": {
        "id": "K9gJCAjXRDzd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tarea de clasificación con el corpus `20newsgroups`**. Probar las siguientes estrategias y en cada caso medir el F1 score:\n",
        "\n",
        "1. Todas las clases, sin quitar *headers*, *quotes*, *footers*. Comparar:\n",
        " * BOW\n",
        " * TF-IDF\n",
        " * BOW + PCA\n",
        " * TF-IDF + PCA\n",
        " * BOW + t-SNE\n",
        " * TF-IDF + t-SNE\n",
        "2. Las mismas 6 estrategias del paso anterior, quitando *headers*, *quotes*, *footers*.\n",
        "3. Escoge dos clases que crees que se diferencien muy bien entre sí con estos modelos. ¿Qué clases escogiste y por qué? Compara BOW y TF-IDF para la clasificación binaria.\n",
        "4. Compara tu clasificador de la tarea pasada con el mejor clasificador del paso 3.\n",
        "5. Escoge ahora dos clases que crees que no se diferencien entre sí con estos modelos. ¿Qué clases escogiste y por qué? Compara BOW y TF-IDF para la clasificación binaria. ¿Qué tanto bajó el rendimiento respecto al paso 3?\n",
        "6. En tu mejor clasificador del paso 3, prueba bajando y subiendo el parámetro `max_features` ¿qué efecto tiene esto en la tarea de clasificación?\n",
        "7. ¿Qué efecto tiene lematizar el texto en la tarea de clasificación? Prueba con tu mejor clasificador binario.\n",
        "\n",
        "En cada uno de los modelos BOW/TF-IDF que construyas puedes ajustar el hiperparámetro `max_features`.\n",
        "\n",
        "**Information Retrieval con el corpus `20newsgroups`** Entrena un modelo BOW y un TF-IDF con todos los documentos juntos de `train` y `test`. Realiza algunas consultas al modelo para obtener los documentos más relevantes para tu busqueda. Reporta algunos casos que creas interesantes y explica porque los consideras interesantes.\n",
        "\n",
        "**Análisis de sentimientos con BOW/TFIDF**. Usando el corpus de la tarea anterior (el de turismo), entrena un clasificador de Machine Learning con los embeddings BOW/TF-IDF, ¿mejora el rendimiento respecto al que presentaste en clase?\n"
      ],
      "metadata": {
        "id": "Q6UXR9lA0NvC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WQFi-8gSRLGJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}