{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYgO3V+dWZNWxKlIVVIeYN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gmauricio-toledo/NLP-LCC/blob/main/Tareas/Tarea%2004.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 14nqDnZ3oDXqRtIcrpB6IP1f_NZP_Gb08"
      ],
      "metadata": {
        "id": "hjx2OkfMi6HG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('YoutubeCommentsDataSet.csv',index_col=0)"
      ],
      "metadata": {
        "id": "lLb2ZCq8lVtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trabajo en clase\n",
        "\n",
        "En esta práctica, exploraremos dos métodos comunes para vectorizar textos en el NLP: **Bag of Words (BOW)** y **TF-IDF**. Utilizaremos implementaciones de `scikit-learn` para llevar a cabo la vectorización y entrenaremos un clasificador para realizar análisis de sentimientos. El objetivo es comparar el rendimiento de ambos métodos bajo diferentes configuraciones.\n",
        "\n",
        "## Instrucciones\n",
        "\n",
        "1. **Preprocesamiento y análisis exploratorio**:\n",
        "   - Realiza la limpieza de los textos que consideres necesario.\n",
        "   - Elimina stopwords si lo consideras necesario.\n",
        "   - Realiza un análisis exploratorio de los datos: distribución de clases, longitud de textos, palabras más frecuentes (puedes usar una nube de palabras o mostrar las palabras más frecuentes por clase).\n",
        "\n",
        "2. **Vectorización de textos**:\n",
        "   - **BOW**: Usa `CountVectorizer` de `scikit-learn` para vectorizar los textos. Prueba con tres valores de `max_features` en órdenes de magnitud distintos.\n",
        "   - **TF-IDF**: Usa `TfidfVectorizer` de `scikit-learn` para vectorizar los textos. Prueba con los mismos tres valores de `max_features` que usaste para BOW.\n",
        "\n",
        "3. **Entrenamiento del clasificador**: Elige un clasificador (por ejemplo, `LogisticRegression`, `DecisionTree`, `Naive Bayes`, etc.) y entrénalo utilizando los datos vectorizados tanto con BOW como con TF-IDF. Cuida los aspectos relacionados con el *data leakage*.\n",
        "\n",
        "4. **Evaluación y reporte**: Para cada combinación de método de vectorización (BOW y TF-IDF) y valor de `max_features`, calcula el F1-score. Reporta los resultados en una tabla como la siguiente:\n",
        "\n",
        "| Método  | max_features | F1-score |\n",
        "|---------|--------------|----------|\n",
        "| BOW     | valor1          |          |\n",
        "| BOW     | valor2         |          |\n",
        "| BOW     | valor3        |          |\n",
        "| TF-IDF  | valor1          |          |\n",
        "| TF-IDF  | valor2         |          |\n",
        "| TF-IDF  | valor3        |          |\n",
        "\n",
        "5. **Conclusiones**: Responde las siguientes preguntas en una celda de texto:\n",
        "   - ¿Cuál método de vectorización (BOW o TF-IDF) obtuvo mejores resultados en general? ¿qué combinación de vectorización y valor de `max_features` produjo el mejor resultado.\n",
        "   - ¿Cómo afecta el valor de `max_features` al rendimiento del modelo?\n",
        "   - ¿Qué estrategias adicionales consideras que podrían mejorar el rendimiento de tu modelo? Describe dos de estas estrategias. **Importante**: Cada estrategia debe ser con BOW/TF-IDF.  \n",
        "   - Describe el proprocesamiento que hiciste en el paso 1."
      ],
      "metadata": {
        "id": "7CNTWPH1lbMt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XamWG1GmlYvZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tarea 4\n",
        "\n",
        "**🔴 Trabajo en parejas**\n",
        "\n",
        "## Instrucciones\n",
        "\n",
        "# Tarea Adicional: Mejorando el Análisis de Sentimientos\n",
        "\n",
        "En esta tarea, profundizarás en el análisis de sentimientos aplicando técnicas avanzadas de preprocesamiento, optimización de modelos y evaluación. Utilizarás el mismo dataset del trabajo en clase original, pero con mejoras en el pipeline y experimentación adicional.\n",
        "\n",
        "## Instrucciones\n",
        "\n",
        "### 1. **Optimización de hiperparámetros**\n",
        "   - Usa `GridSearchCV` o `RandomizedSearchCV` de `scikit-learn` para optimizar hiperparámetros del clasificador que elegiste en la práctica original (por ejemplo, `C` en `LogisticRegression` o `alpha` en `Naive Bayes`). Optimiza también el parámetro `max_features` del vectorizador que hayas elegido.\n",
        "   - Prueba al menos 3 valores diferentes para cada hiperparámetro.\n",
        "   - Reporta los mejores hiperparámetros encontrados y el F1-score obtenido con ellos.\n",
        "\n",
        "### 2. **Lematización y n-gramas**\n",
        "   - Usa `spaCy` para aplicar lematización a los textos antes de la vectorización.\n",
        "   - Experimenta con la inclusión de n-gramas (bigramas y trigramas) en la vectorización con `CountVectorizer` y `TfidfVectorizer`.\n",
        "   - Prueba las siguientes combinaciones:\n",
        "     - Sólo unigramas con lematización.\n",
        "     - Unigramas y bigramas con lematización.\n",
        "   - Reporta el F1-score para cada combinación.\n",
        "\n",
        "### 3. **Prueba con otros clasificadores**\n",
        "   - Entrena y evalúa al menos dos clasificadores adicionales (por ejemplo, `Random Forest`, `SVM`, `DecisionTree`, `MLPClassifier`, `XGBoost` etc).\n",
        "   - Compara los resultados con los obtenidos usando el clasificador original.\n",
        "   - Reporta el F1-score para cada clasificador.\n",
        "\n",
        "### 4. **Manejo de datos desbalanceados**\n",
        "   - El dataset está desbalanceado, aplica las siguientes técnicas:\n",
        "     - **Undersampling**: Reduce la clase mayoritaria para equilibrar las clases.\n",
        "     - **Oversampling**: Utiliza SMOTE, o alguna técnica similar, para aumentar la clase minoritaria.\n",
        "   - Entrena el modelo con los datos balanceados y compara los resultados con el dataset original.\n",
        "   - Reporta el F1-score para cada técnica.\n",
        "\n",
        "### 5. **Visualización de resultados**\n",
        "   - Usa `matplotlib` para crear un gráfico que muestre cómo varía el F1-score en función de `max_features` (utiliza varios datos espaciados apropiadamente).\n",
        "   - Incluye en el gráfico las curvas para ambos métodos de vectorización (BOW y TF-IDF).\n",
        "   - Asegúrate de que el gráfico tenga:\n",
        "     - Título descriptivo.\n",
        "     - Etiquetas en los ejes (eje X: `max_features`, eje Y: `F1-score`).\n",
        "     - Leyenda que distinga entre BOW y TF-IDF.\n",
        "\n",
        "## Reporte Final\n",
        "\n",
        "En una celda de texto al final incluye lo siguiente:\n",
        "\n",
        "1. **Resultados numéricos**:\n",
        "   - Tabla con los F1-scores obtenidos en cada experimento (optimización de hiperparámetros, lematización, n-gramas, otros clasificadores, balanceo de datos).\n",
        "\n",
        "   Ejemplo:\n",
        "\n",
        "| Técnica                     | F1-score |\n",
        "|-----------------------------|----------|\n",
        "| Optimización de hiperparámetros | 0.89     |\n",
        "| Lematización + unigramas     | 0.87     |\n",
        "| Lematización + bigramas      | 0.88     |\n",
        "| Random Forest                | 0.90     |\n",
        "| SVM                          | 0.91     |\n",
        "| Undersampling                | 0.85     |\n",
        "| Oversampling (SMOTE)         | 0.89     |\n",
        "...\n",
        "\n",
        "\n",
        "2. **Análisis y conclusiones**:\n",
        "   - ¿Qué combinación de técnicas (preprocesamiento, vectorización, clasificador) obtuvo los mejores resultados?\n",
        "   - ¿Qué estrategias adeicionales podrías probar?\n"
      ],
      "metadata": {
        "id": "Sd3QgdTxuPc1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1r21djeGuSQ3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}