{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYgO3V+dWZNWxKlIVVIeYN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gmauricio-toledo/NLP-LCC/blob/main/Tareas/Tarea%2004.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 14nqDnZ3oDXqRtIcrpB6IP1f_NZP_Gb08"
      ],
      "metadata": {
        "id": "hjx2OkfMi6HG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('YoutubeCommentsDataSet.csv',index_col=0)"
      ],
      "metadata": {
        "id": "lLb2ZCq8lVtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trabajo en clase\n",
        "\n",
        "En esta pr谩ctica, exploraremos dos m茅todos comunes para vectorizar textos en el NLP: **Bag of Words (BOW)** y **TF-IDF**. Utilizaremos implementaciones de `scikit-learn` para llevar a cabo la vectorizaci贸n y entrenaremos un clasificador para realizar an谩lisis de sentimientos. El objetivo es comparar el rendimiento de ambos m茅todos bajo diferentes configuraciones.\n",
        "\n",
        "## Instrucciones\n",
        "\n",
        "1. **Preprocesamiento y an谩lisis exploratorio**:\n",
        "   - Realiza la limpieza de los textos que consideres necesario.\n",
        "   - Elimina stopwords si lo consideras necesario.\n",
        "   - Realiza un an谩lisis exploratorio de los datos: distribuci贸n de clases, longitud de textos, palabras m谩s frecuentes (puedes usar una nube de palabras o mostrar las palabras m谩s frecuentes por clase).\n",
        "\n",
        "2. **Vectorizaci贸n de textos**:\n",
        "   - **BOW**: Usa `CountVectorizer` de `scikit-learn` para vectorizar los textos. Prueba con tres valores de `max_features` en 贸rdenes de magnitud distintos.\n",
        "   - **TF-IDF**: Usa `TfidfVectorizer` de `scikit-learn` para vectorizar los textos. Prueba con los mismos tres valores de `max_features` que usaste para BOW.\n",
        "\n",
        "3. **Entrenamiento del clasificador**: Elige un clasificador (por ejemplo, `LogisticRegression`, `DecisionTree`, `Naive Bayes`, etc.) y entr茅nalo utilizando los datos vectorizados tanto con BOW como con TF-IDF. Cuida los aspectos relacionados con el *data leakage*.\n",
        "\n",
        "4. **Evaluaci贸n y reporte**: Para cada combinaci贸n de m茅todo de vectorizaci贸n (BOW y TF-IDF) y valor de `max_features`, calcula el F1-score. Reporta los resultados en una tabla como la siguiente:\n",
        "\n",
        "| M茅todo  | max_features | F1-score |\n",
        "|---------|--------------|----------|\n",
        "| BOW     | valor1          |          |\n",
        "| BOW     | valor2         |          |\n",
        "| BOW     | valor3        |          |\n",
        "| TF-IDF  | valor1          |          |\n",
        "| TF-IDF  | valor2         |          |\n",
        "| TF-IDF  | valor3        |          |\n",
        "\n",
        "5. **Conclusiones**: Responde las siguientes preguntas en una celda de texto:\n",
        "   - 驴Cu谩l m茅todo de vectorizaci贸n (BOW o TF-IDF) obtuvo mejores resultados en general? 驴qu茅 combinaci贸n de vectorizaci贸n y valor de `max_features` produjo el mejor resultado.\n",
        "   - 驴C贸mo afecta el valor de `max_features` al rendimiento del modelo?\n",
        "   - 驴Qu茅 estrategias adicionales consideras que podr铆an mejorar el rendimiento de tu modelo? Describe dos de estas estrategias. **Importante**: Cada estrategia debe ser con BOW/TF-IDF.  \n",
        "   - Describe el proprocesamiento que hiciste en el paso 1."
      ],
      "metadata": {
        "id": "7CNTWPH1lbMt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XamWG1GmlYvZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tarea 4\n",
        "\n",
        "** Trabajo en parejas**\n",
        "\n",
        "## Instrucciones\n",
        "\n",
        "# Tarea Adicional: Mejorando el An谩lisis de Sentimientos\n",
        "\n",
        "En esta tarea, profundizar谩s en el an谩lisis de sentimientos aplicando t茅cnicas avanzadas de preprocesamiento, optimizaci贸n de modelos y evaluaci贸n. Utilizar谩s el mismo dataset del trabajo en clase original, pero con mejoras en el pipeline y experimentaci贸n adicional.\n",
        "\n",
        "## Instrucciones\n",
        "\n",
        "### 1. **Optimizaci贸n de hiperpar谩metros**\n",
        "   - Usa `GridSearchCV` o `RandomizedSearchCV` de `scikit-learn` para optimizar hiperpar谩metros del clasificador que elegiste en la pr谩ctica original (por ejemplo, `C` en `LogisticRegression` o `alpha` en `Naive Bayes`). Optimiza tambi茅n el par谩metro `max_features` del vectorizador que hayas elegido.\n",
        "   - Prueba al menos 3 valores diferentes para cada hiperpar谩metro.\n",
        "   - Reporta los mejores hiperpar谩metros encontrados y el F1-score obtenido con ellos.\n",
        "\n",
        "### 2. **Lematizaci贸n y n-gramas**\n",
        "   - Usa `spaCy` para aplicar lematizaci贸n a los textos antes de la vectorizaci贸n.\n",
        "   - Experimenta con la inclusi贸n de n-gramas (bigramas y trigramas) en la vectorizaci贸n con `CountVectorizer` y `TfidfVectorizer`.\n",
        "   - Prueba las siguientes combinaciones:\n",
        "     - S贸lo unigramas con lematizaci贸n.\n",
        "     - Unigramas y bigramas con lematizaci贸n.\n",
        "   - Reporta el F1-score para cada combinaci贸n.\n",
        "\n",
        "### 3. **Prueba con otros clasificadores**\n",
        "   - Entrena y eval煤a al menos dos clasificadores adicionales (por ejemplo, `Random Forest`, `SVM`, `DecisionTree`, `MLPClassifier`, `XGBoost` etc).\n",
        "   - Compara los resultados con los obtenidos usando el clasificador original.\n",
        "   - Reporta el F1-score para cada clasificador.\n",
        "\n",
        "### 4. **Manejo de datos desbalanceados**\n",
        "   - El dataset est谩 desbalanceado, aplica las siguientes t茅cnicas:\n",
        "     - **Undersampling**: Reduce la clase mayoritaria para equilibrar las clases.\n",
        "     - **Oversampling**: Utiliza SMOTE, o alguna t茅cnica similar, para aumentar la clase minoritaria.\n",
        "   - Entrena el modelo con los datos balanceados y compara los resultados con el dataset original.\n",
        "   - Reporta el F1-score para cada t茅cnica.\n",
        "\n",
        "### 5. **Visualizaci贸n de resultados**\n",
        "   - Usa `matplotlib` para crear un gr谩fico que muestre c贸mo var铆a el F1-score en funci贸n de `max_features` (utiliza varios datos espaciados apropiadamente).\n",
        "   - Incluye en el gr谩fico las curvas para ambos m茅todos de vectorizaci贸n (BOW y TF-IDF).\n",
        "   - Aseg煤rate de que el gr谩fico tenga:\n",
        "     - T铆tulo descriptivo.\n",
        "     - Etiquetas en los ejes (eje X: `max_features`, eje Y: `F1-score`).\n",
        "     - Leyenda que distinga entre BOW y TF-IDF.\n",
        "\n",
        "## Reporte Final\n",
        "\n",
        "En una celda de texto al final incluye lo siguiente:\n",
        "\n",
        "1. **Resultados num茅ricos**:\n",
        "   - Tabla con los F1-scores obtenidos en cada experimento (optimizaci贸n de hiperpar谩metros, lematizaci贸n, n-gramas, otros clasificadores, balanceo de datos).\n",
        "\n",
        "   Ejemplo:\n",
        "\n",
        "| T茅cnica                     | F1-score |\n",
        "|-----------------------------|----------|\n",
        "| Optimizaci贸n de hiperpar谩metros | 0.89     |\n",
        "| Lematizaci贸n + unigramas     | 0.87     |\n",
        "| Lematizaci贸n + bigramas      | 0.88     |\n",
        "| Random Forest                | 0.90     |\n",
        "| SVM                          | 0.91     |\n",
        "| Undersampling                | 0.85     |\n",
        "| Oversampling (SMOTE)         | 0.89     |\n",
        "...\n",
        "\n",
        "\n",
        "2. **An谩lisis y conclusiones**:\n",
        "   - 驴Qu茅 combinaci贸n de t茅cnicas (preprocesamiento, vectorizaci贸n, clasificador) obtuvo los mejores resultados?\n",
        "   - 驴Qu茅 estrategias adeicionales podr铆as probar?\n"
      ],
      "metadata": {
        "id": "Sd3QgdTxuPc1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1r21djeGuSQ3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}